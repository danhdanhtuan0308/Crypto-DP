# Dockerfile for Airflow scheduler
FROM apache/airflow:2.8.1-python3.11

USER root
RUN apt-get update && \
    apt-get install -y --no-install-recommends build-essential curl && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

USER airflow

# Copy requirements and install
COPY requirements.txt /tmp/
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# Copy the ETL code (needed by DAG)
COPY raw_webhook_to_gcs.py /opt/airflow/

# Copy DAGs
COPY dags /opt/airflow/dags

WORKDIR /opt/airflow

ENV PYTHONUNBUFFERED=1
ENV AIRFLOW_HOME=/opt/airflow
ENV AIRFLOW__CORE__EXECUTOR=SequentialExecutor
ENV AIRFLOW__CORE__LOAD_EXAMPLES=False
ENV AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
ENV AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
ENV AIRFLOW__WEBSERVER__WEB_SERVER_PORT=8080

# Default credentials (override via environment variables)
ENV AIRFLOW_USERNAME=cryptodp
ENV AIRFLOW_PASSWORD=CryptoDP2025

# Expose port 8080 for Airflow webserver
EXPOSE 8080

# Initialize Airflow DB and start services
CMD ["bash", "-c", "airflow db init && airflow users create --username ${AIRFLOW_USERNAME} --password ${AIRFLOW_PASSWORD} --firstname Crypto --lastname Admin --role Admin --email admin@cryptodp.com || true && airflow webserver -p 8080 & airflow scheduler"]
